{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterative Training\n",
    "\n",
    "This is the step-by-step iterative visual model training based on the crawled data.\n",
    "\n",
    "Based on how many pictures are needed for the crawl, there will be different number of models trained for filtering against the image candidates.\n",
    "\n",
    "The precision will be measured afterwords for each iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Data samples from multiple sources\n",
    "\n",
    "1. 100 seed images from google image\n",
    "2. 1000 images from google and possibly Flickr\n",
    "3. 10000 images from google, Flickr\n",
    "\"\"\"\n",
    "\n",
    "# 485 results from google image search\n",
    "results_google = '../tasks/03.image-crawl/result-wse_google_bird.jsonl'\n",
    "\n",
    "# 119784 results with good varieties, serving as negative examples\n",
    "results_non_samples = '../tasks/03.image-crawl/result-wse_non_samples-100k.jsonl'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plow multiple images\n",
    "\n",
    "\"\"\"\n",
    "plot image matrix\n",
    "\"\"\"\n",
    "\n",
    "# plot 3x3 picture matrix\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import StringIO\n",
    "from matplotlib.pyplot import figure, show, axes, sci\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def thumbnail(img, size=250):\n",
    "    \"\"\" generate size x size square thumbnail \"\"\"\n",
    "    \n",
    "    THUMB_SIZE = size, size\n",
    "    width, height = img.size\n",
    "\n",
    "    if width > height:\n",
    "        delta = width - height\n",
    "        left = int(delta/2)\n",
    "        upper = 0\n",
    "        right = height + left\n",
    "        lower = height\n",
    "    else:\n",
    "        delta = height - width\n",
    "        left = 0\n",
    "        upper = int(delta/2)\n",
    "        right = width\n",
    "        lower = width + upper\n",
    "\n",
    "    img = img.crop((left, upper, right, lower))\n",
    "    img.thumbnail(THUMB_SIZE, Image.ANTIALIAS)\n",
    "    \n",
    "    return img\n",
    "\n",
    "\n",
    "def plot_3x3(images, title = ''):\n",
    "    \"\"\"\n",
    "    given 9 images, plot them in 3x3 matrix\n",
    "    \"\"\"\n",
    "\n",
    "    plt.figure(figsize=(10,10))\n",
    "    \n",
    "    Nr = 3\n",
    "    Nc = 3\n",
    "    i = 0\n",
    "    \n",
    "    for image in images:\n",
    "        try:\n",
    "            img_io = requests.get(image)\n",
    "            image = Image.open(StringIO.StringIO(img_io.content))\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "        i += 1\n",
    "        plt.subplot(Nr, Nc, i)\n",
    "        image = thumbnail(image)\n",
    "        \n",
    "        #img = io.imread(StringIO.StringIO(img_io.content))\n",
    "        plt.imshow(image)\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def plot_images(images, title = '', nrow=3, ncol=3):\n",
    "    \"\"\"\n",
    "    given 9 images, plot them in 3x3 matrix\n",
    "    \"\"\"\n",
    "\n",
    "    # force truncate the image array\n",
    "    images = images[:nrow*ncol]\n",
    "    \n",
    "    plt.figure(figsize=(20,20))\n",
    "    \n",
    "    Nr = nrow\n",
    "    Nc = ncol\n",
    "    i = 0\n",
    "    \n",
    "    for image in images:\n",
    "        \n",
    "        try:\n",
    "            img_io = requests.get(image)\n",
    "            image = Image.open(StringIO.StringIO(img_io.content))\n",
    "            image = thumbnail(image, size=100)\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "        i += 1\n",
    "        plt.subplot(Nr, Nc, i)\n",
    "        plt.imshow(image)\n",
    "    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#\n",
    "# load samples\n",
    "#\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "def load_samples(filename, num=None, labels=[]):\n",
    "    \"\"\" read predicted results from file \"\"\"\n",
    "    \n",
    "    if not os.path.exists(filename):\n",
    "        print 'file not exist %s' % filename\n",
    "        return\n",
    "    \n",
    "    items = []\n",
    "    with open(filename) as fdr:\n",
    "        for line in fdr:\n",
    "            line = line.strip()\n",
    "            try:\n",
    "                item = json.loads(line)\n",
    "            except:\n",
    "                continue\n",
    "            if not item.get('embeds') or len(item.get('embeds')) != 1024:\n",
    "                continue\n",
    "            if labels != [] and set(labels).intersection(item.get('tags')) == set():\n",
    "                continue\n",
    "\n",
    "            items.append(item)\n",
    "            if num is not None and len(items) == num:\n",
    "                break\n",
    "\n",
    "    return items\n",
    "\n",
    "# load positive examples\n",
    "results = load_samples(results_google, 100)\n",
    "\n",
    "print 'number of samples loaded:'\n",
    "print len(results)\n",
    "\n",
    "seed_urls = [sample['url'] for sample in results]\n",
    "seed_tags = [sample['tags'] for sample in results]\n",
    "seed_samples = [sample['embeds'] for sample in results]\n",
    "seed_samples = np.array(seed_samples)\n",
    "print seed_samples.shape\n",
    "\n",
    "# load negative examples\n",
    "results = load_samples(results_non_samples, 100)\n",
    "neg_urls = [sample['url'] for sample in results]\n",
    "neg_samples = [sample['embeds'] for sample in results]\n",
    "neg_samples = np.array(neg_samples)\n",
    "print neg_samples.shape\n",
    "\n",
    "# load test examples\n",
    "results = load_samples(results_google)\n",
    "results = results[-50:]\n",
    "\n",
    "results2 = load_samples(results_non_samples, 50)\n",
    "\n",
    "results += results2\n",
    "\n",
    "test_urls = [sample['url'] for sample in results]\n",
    "test_samples = [sample['embeds'] for sample in results]\n",
    "test_samples = np.array(test_samples)\n",
    "\n",
    "print test_samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "run K-means to cluster the seed crawl to 3 clusters\n",
    "then rule out the clusters with less than 5% population\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import datasets\n",
    "\n",
    "np.random.seed(5)\n",
    "\n",
    "from time import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "# cluster the data\n",
    "\n",
    "data = scale(seed_samples)\n",
    "n_samples, n_features = data.shape\n",
    "k = 3\n",
    "\n",
    "k_means = KMeans(init='k-means++', n_clusters=k, n_init=10)\n",
    "k_means.fit(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check the clustered data\n",
    "\n",
    "clustered_urls = []\n",
    "\n",
    "it = np.nditer(k_means.labels_, flags=['f_index'])\n",
    "\n",
    "while not it.finished:\n",
    "    clustered_urls.append([])\n",
    "    clustered_urls[it[0]].append(seed_urls[it.index])\n",
    "    it.iternext()\n",
    "\n",
    "for idx in range(k):\n",
    "    print 'count for %d: %d' % (idx, len(clustered_urls[idx]))\n",
    "\n",
    "for cat in range(k):\n",
    "    img_urls = clustered_urls[cat][:9]\n",
    "    print 'cluster %d' % cat\n",
    "    plot_3x3(img_urls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# clean and rebalanced the samples\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "ids_excl = []\n",
    "for idx in range(k):\n",
    "    cnt = np.sum(k_means.labels_ == idx)\n",
    "    if cnt < len(k_means.labels_) * 0.05:\n",
    "        for idid in np.where(k_means.labels_ == idx)[0]:\n",
    "            ids_excl.append(idid)\n",
    "\n",
    "ids_excl = sorted(ids_excl, reverse=True)\n",
    "\n",
    "for idid in ids_excl:\n",
    "    del seed_tags[idid]\n",
    "    del seed_urls[idid]\n",
    "    seed_samples = np.delete(seed_samples, idid, 0)\n",
    "\n",
    "# check the samples\n",
    "print seed_samples.shape\n",
    "print len(seed_tags)\n",
    "print len(seed_urls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot the positive images for visual inspection\n",
    "\n",
    "plot_images(seed_urls, nrow=10, ncol=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train the model0\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "npos, _ = seed_samples.shape\n",
    "nneg, _ = neg_samples.shape\n",
    "\n",
    "print npos, nneg\n",
    "\n",
    "train_data = np.append(seed_samples, neg_samples, 0)\n",
    "train_label = np.array([1] * npos + [2] * nneg)\n",
    "\n",
    "print train_data.shape\n",
    "print train_label.shape\n",
    "\n",
    "print len(train_data)\n",
    "print len(train_label)\n",
    "\n",
    "assert(len(train_data) == len(train_label))\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(train_data, train_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "test the model0\n",
    "with positive and negative samples\n",
    "\"\"\"\n",
    "\n",
    "print 'test positive samples:'\n",
    "for test_feature in test_samples[:50]:\n",
    "    print(clf.predict_proba(test_feature))\n",
    "plot_3x3(test_urls[:9])\n",
    "\n",
    "print 'test negative samples:'\n",
    "for test_feature in test_samples[-50:]:\n",
    "    print(clf.predict_proba(test_feature))\n",
    "plot_3x3(test_urls[-9:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "2nd iteration\n",
    "\n",
    "1. predict 1k+ until get 1k positive\n",
    "2. train on the 1k positives\n",
    "3. test\n",
    "\"\"\"\n",
    "\n",
    "# results from flickr\n",
    "results_flickr_10k = '../tasks/03.image-crawl/result-wse_flickr_bird_10k.jsonl'\n",
    "\n",
    "# load positive examples\n",
    "results = load_samples(results_google)\n",
    "results = results[100:]\n",
    "\n",
    "results_flickr = load_samples(results_flickr_10k)\n",
    "results += results_flickr\n",
    "\n",
    "seed_urls = [sample['url'] for sample in results]\n",
    "seed_tags = [sample['tags'] for sample in results]\n",
    "seed_samples = [sample['embeds'] for sample in results]\n",
    "seed_samples = np.array(seed_samples)\n",
    "\n",
    "print '%d number of samples loaded:' % len(results)\n",
    "\n",
    "cnt = 0\n",
    "pos_ids = []\n",
    "neg_ids = []\n",
    "for idx in range(len(seed_urls)):\n",
    "    if clf.predict_proba(seed_samples[idx])[0][0] > 0.80:\n",
    "        pos_ids.append(idx)\n",
    "        cnt += 1\n",
    "        if cnt == 1000:\n",
    "            break\n",
    "    else:\n",
    "        neg_ids.append(idx)\n",
    "\n",
    "import random\n",
    "import copy\n",
    "\n",
    "random.shuffle(neg_ids)\n",
    "pos_idx_copy = copy.copy(pos_ids)\n",
    "random.shuffle(pos_idx_copy)\n",
    "\n",
    "print \"%d positive samples from %d candidates\" % (cnt, idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_data_samples(datasets, idsets):\n",
    "    \"\"\" subset the datasets with a group of ids \"\"\"\n",
    "    results = []\n",
    "    for idx in idsets:\n",
    "        results.append(datasets[idx])\n",
    "    return results\n",
    "\n",
    "pos_urls = make_data_samples(seed_urls, pos_idx_copy)\n",
    "neg_urls = make_data_samples(seed_urls, neg_ids)\n",
    "\n",
    "plot_3x3(pos_urls[:9])\n",
    "\n",
    "plot_3x3(neg_urls[:9])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_images(pos_urls, nrow=10, ncol=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# make the training data for \n",
    "# iteration 2\n",
    "# with 1k positive and 1k negative\n",
    "\n",
    "# make positive samples\n",
    "results_pos = make_data_samples(results, pos_ids)\n",
    "\n",
    "seed_urls = [sample['url'] for sample in results_pos]\n",
    "seed_tags = [sample['tags'] for sample in results_pos]\n",
    "seed_samples = [sample['embeds'] for sample in results_pos]\n",
    "seed_samples = np.array(seed_samples)\n",
    "\n",
    "print seed_samples.shape\n",
    "\n",
    "# make negative samples\n",
    "results_neg = load_samples(results_non_samples, 1000)\n",
    "neg_urls = [sample['url'] for sample in results_neg]\n",
    "neg_samples = [sample['embeds'] for sample in results_neg]\n",
    "neg_samples = np.array(neg_samples)\n",
    "print neg_samples.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#\n",
    "# train the 2nd model with 1k+1k\n",
    "#\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "npos, _ = seed_samples.shape\n",
    "nneg, _ = neg_samples.shape\n",
    "\n",
    "print npos, nneg\n",
    "\n",
    "train_data = np.append(seed_samples, neg_samples, 0)\n",
    "train_label = np.array([1] * npos + [2] * nneg)\n",
    "\n",
    "print train_data.shape\n",
    "print train_label.shape\n",
    "\n",
    "print len(train_data)\n",
    "print len(train_label)\n",
    "\n",
    "assert(len(train_data) == len(train_label))\n",
    "\n",
    "clf2 = LogisticRegression()\n",
    "clf2.fit(train_data, train_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "test the model1\n",
    "with positive and negative samples\n",
    "\"\"\"\n",
    "\n",
    "print 'test positive samples:'\n",
    "for test_feature in test_samples[:50]:\n",
    "    print(clf2.predict_proba(test_feature))\n",
    "plot_3x3(test_urls[10:18])\n",
    "\n",
    "print 'test negative samples:'\n",
    "for test_feature in test_samples[-50:]:\n",
    "    print(clf2.predict_proba(test_feature))\n",
    "plot_3x3(test_urls[-9:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "3rd iteration, to 10k positives\n",
    "\"\"\"\n",
    "\n",
    "# results from flickr\n",
    "results_flickr_100k = '../tasks/03.image-crawl/result-wse_flickr_bird_200k.jsonl'\n",
    "\n",
    "# load positive examples\n",
    "results = load_samples(results_google)\n",
    "\n",
    "results_flickr = load_samples(results_flickr_100k, 20000)\n",
    "results += results_flickr\n",
    "\n",
    "seed_urls = [sample['url'] for sample in results]\n",
    "seed_tags = [sample['tags'] for sample in results]\n",
    "seed_samples = [sample['embeds'] for sample in results]\n",
    "seed_samples = np.array(seed_samples)\n",
    "\n",
    "print '%d number of samples loaded:' % len(results)\n",
    "\n",
    "cnt = 0\n",
    "pos_ids = []\n",
    "for idx in range(len(seed_urls)):\n",
    "    if clf2.predict_proba(seed_samples[idx])[0][0] > 0.99:\n",
    "        pos_ids.append(idx)\n",
    "        cnt += 1\n",
    "        if cnt == 10000:\n",
    "            break\n",
    "\n",
    "print \"%d positive samples from %d candidates\" % (cnt, idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# make the training data for \n",
    "# iteration 3\n",
    "# with 10k positive and 10k negative\n",
    "\n",
    "# make positive samples\n",
    "results_pos = make_data_samples(results, pos_ids)\n",
    "\n",
    "seed_urls = [sample['url'] for sample in results_pos]\n",
    "seed_tags = [sample['tags'] for sample in results_pos]\n",
    "seed_samples = [sample['embeds'] for sample in results_pos]\n",
    "seed_samples = np.array(seed_samples)\n",
    "\n",
    "print seed_samples.shape\n",
    "\n",
    "# make negative samples\n",
    "results_neg = load_samples(results_non_samples, len(seed_urls))\n",
    "neg_urls = [sample['url'] for sample in results_neg]\n",
    "neg_samples = [sample['embeds'] for sample in results_neg]\n",
    "neg_samples = np.array(neg_samples)\n",
    "print neg_samples.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_images(seed_urls, nrow=10, ncol=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#\n",
    "# train the 3nd model with 10k+10k\n",
    "#\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "npos, _ = seed_samples.shape\n",
    "nneg, _ = neg_samples.shape\n",
    "\n",
    "print npos, nneg\n",
    "\n",
    "train_data = np.append(seed_samples, neg_samples, 0)\n",
    "train_label = np.array([1] * npos + [2] * nneg)\n",
    "\n",
    "print train_data.shape\n",
    "print train_label.shape\n",
    "\n",
    "print len(train_data)\n",
    "print len(train_label)\n",
    "\n",
    "assert(len(train_data) == len(train_label))\n",
    "\n",
    "clf3 = LogisticRegression()\n",
    "clf3.fit(train_data, train_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "test the model1\n",
    "with positive and negative samples\n",
    "\"\"\"\n",
    "\n",
    "print 'test positive samples:'\n",
    "for test_feature in test_samples[:50]:\n",
    "    print(clf3.predict_proba(test_feature))\n",
    "plot_3x3(test_urls[10:18])\n",
    "\n",
    "print 'test negative samples:'\n",
    "for test_feature in test_samples[-50:]:\n",
    "    print(clf3.predict_proba(test_feature))\n",
    "plot_3x3(test_urls[-9:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "4th iteration, to 100k positives\n",
    "\"\"\"\n",
    "\n",
    "# results from flickr\n",
    "results_flickr_100k = '../tasks/03.image-crawl/result-wse_flickr_bird_200k.jsonl'\n",
    "\n",
    "# load positive examples\n",
    "results = load_samples(results_google)\n",
    "\n",
    "results_flickr = load_samples(results_flickr_100k)\n",
    "results += results_flickr\n",
    "\n",
    "seed_urls = [sample['url'] for sample in results]\n",
    "seed_tags = [sample['tags'] for sample in results]\n",
    "seed_samples = [sample['embeds'] for sample in results]\n",
    "seed_samples = np.array(seed_samples)\n",
    "\n",
    "print '%d number of samples loaded:' % len(results)\n",
    "\n",
    "cnt = 0\n",
    "pos_ids = []\n",
    "for idx in range(len(seed_urls)):\n",
    "    if clf3.predict_proba(seed_samples[idx])[0][0] > 0.99:\n",
    "        pos_ids.append(idx)\n",
    "        cnt += 1\n",
    "        if cnt == 100000:\n",
    "            break\n",
    "\n",
    "print \"%d positive samples from %d candidates\" % (cnt, idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# make the training data for \n",
    "# iteration 4\n",
    "# with 100k positive and 100k negative\n",
    "\n",
    "# make positive samples\n",
    "results_pos = make_data_samples(results, pos_ids)\n",
    "\n",
    "seed_urls = [sample['url'] for sample in results_pos]\n",
    "seed_tags = [sample['tags'] for sample in results_pos]\n",
    "seed_samples = [sample['embeds'] for sample in results_pos]\n",
    "seed_samples = np.array(seed_samples)\n",
    "\n",
    "print seed_samples.shape\n",
    "\n",
    "# make negative samples\n",
    "results_neg = load_samples(results_non_samples, len(seed_urls))\n",
    "neg_urls = [sample['url'] for sample in results_neg]\n",
    "neg_samples = [sample['embeds'] for sample in results_neg]\n",
    "neg_samples = np.array(neg_samples)\n",
    "print neg_samples.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# train the 4th model with 100k+100k\n",
    "#\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "npos, _ = seed_samples.shape\n",
    "nneg, _ = neg_samples.shape\n",
    "\n",
    "print npos, nneg\n",
    "\n",
    "train_data = np.append(seed_samples, neg_samples, 0)\n",
    "train_label = np.array([1] * npos + [2] * nneg)\n",
    "\n",
    "print train_data.shape\n",
    "print train_label.shape\n",
    "\n",
    "print len(train_data)\n",
    "print len(train_label)\n",
    "\n",
    "assert(len(train_data) == len(train_label))\n",
    "\n",
    "clf4 = LogisticRegression()\n",
    "clf4.fit(train_data, train_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "test the model1\n",
    "with positive and negative samples\n",
    "\"\"\"\n",
    "\n",
    "print 'test positive samples:'\n",
    "for test_feature in test_samples[:50]:\n",
    "    print(clf4.predict_proba(test_feature))\n",
    "plot_3x3(test_urls[10:18])\n",
    "\n",
    "print 'test negative samples:'\n",
    "for test_feature in test_samples[-50:]:\n",
    "    print(clf4.predict_proba(test_feature))\n",
    "plot_3x3(test_urls[-9:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "pos_urls = copy.copy(seed_urls)\n",
    "\n",
    "import random\n",
    "random.shuffle(pos_urls)\n",
    "\n",
    "pos_urls = pos_urls[:100]\n",
    "print pos_urls\n",
    "\n",
    "print len(pos_urls)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_images(pos_urls, nrow=10, ncol=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
